{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PhysBench Beginner's Guide  \n",
    "In this tutorial, you will learn about the basic concepts of this framework and how to train a basic rPPG model. \n",
    "## Prepare the datasets\n",
    "First, you need to organize the datasets. We assume that you have already obtained the UBFC (UBFC-rPPG-2) and PURE datasets. \n",
    "### Configuration file directory \n",
    "Please fill in the folder directory of UBFC and PURE datasets in the `config.py` file. In addition, you need to set up a tmp directory, which will store the temporary files generated by this framework. It is recommended to set it on SSD and reserve sufficient available space to ensure the speed of training and testing.\n",
    "### Generate face detection cache (non-essential step) \n",
    "Please use dataset_generate_cache.py to parallelize face detection and generate cache, which will greatly speed up the dataset processing progress. \n",
    "Before processing the dataset, please make sure it is complete and no files are damaged. It is not recommended to perform this step on a Hard Disk Drive (HDD), as high-intensity reading may cause disk failure.  \n",
    "If you skip this step, generating the dataset will take longer. However, the face detection cache will still be created, but it is single-threaded and slower. When you need to generate the dataset again, the cache will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.popen('python dataset_generate_cache.py').read()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: If you encounter an error when generating the PURE dataset, this is usually caused by some corrupted PNG files that cannot be read. Please check if your dataset is complete and it's best to decompress it again."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate UBFC and PURE standard dataset files  \n",
    "When generating a dataset, it may be necessary to add some additional labels, such as marking skin color, motion, illumination, etc. A simple example is labeling the training set and validation set; just store the required labels in the `labels`.  \n",
    "\n",
    "We used the first 49 videos of the PURE dataset for training, the last 10 videos for validation, and the entire UBFC dataset for testing.  \n",
    "\n",
    "Once the dataset is generated, you should not need to generate it again. You can use it repeatedly to create new training data or for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dataset pure_dataset.h5 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [15:36<00:00, 15.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dataset ubfc_dataset.h5 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:03<00:00, 12.89it/s]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") #Add the parent directory to the environment to import files from the parent directory.\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "\n",
    "df = pd.read_csv('PURE_dataset_index.csv')\n",
    "files_pure = df['file']\n",
    "labels = [{'fold':'train'}]*49+[{'fold':'valid'}]*10 #Divide the training set and validation set\n",
    "dump_dataset(\"pure_dataset.h5\", files_pure, loader_pure, labels=labels)\n",
    "\n",
    "df = pd.read_csv('UBFC_rPPG2_dataset_index.csv')\n",
    "files_ubfc = df['file']\n",
    "dump_dataset(\"ubfc_dataset.h5\", files_ubfc, loader_ubfc_rppg2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate datatape for training and validation  \n",
    "\n",
    "Your model will be trained on PURE, so we need to use PURE to generate training and validation tape. The algorithm will slice the video every `step` seconds along each video, cutting the video into a shape specified by the `shape`. In addition, there is a data augmentation option `extend_rate` and `extend_hr`, which allows the algorithm to scale in time and produce additional different heart rate segments. `extend_rate` determines the number of additional segments compared to the original segment, while `extend_hr` is the range of enhanced heart rates. The `fold` specifies training set and validation set which were defined in `labels` in previous step. Please use `cv2.INTER_AREA` for `sample` as it's useful for low-resolution models and small datasets. If you have a large training set or higher resolution model, you may not need it.  \n",
    "\n",
    "This model uses a 32x8x8 input, which means a resolution of 8x8 and 32 frames, it's a very small input.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating datatape train_tape.h5 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:26<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating datatape valid_tape.h5 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:16<00:00,  3.50it/s]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils import *\n",
    "dump_datatape(\"pure_dataset.h5\", \"train_tape.h5\", shape=(32, 8, 8), step=1, extend_rate=1, extend_hr=(40, 150), fold='train', sample=cv2.INTER_AREA)\n",
    "dump_datatape(\"pure_dataset.h5\", \"valid_tape.h5\", shape=(32, 8, 8), step=1, extend_rate=0, fold='valid', sample=cv2.INTER_AREA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training data for the model  \n",
    "\n",
    "Use load_datatape to load datatape, which becomes a generator object after loading. However, the model cannot use it directly for training; it needs to be wrapped as a TensorFlow dataset using `to_tf`. When using the dataset, you can add `.cache()`, which allows caching all datasets into memory. Since our training data is small, this is feasible. In addition, cache can take parameters; using `.cache(cache_file_path)` can cache on high-speed SSDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils import *\n",
    "import tensorflow as tf\n",
    "# This step prevents TensorFlow from using all the GPU memory, and instead gradually allocates memory as needed, which slightly reduces speed.\n",
    "for i in tf.config.experimental.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(i,True)\n",
    "\n",
    "def to_tf(datatape, dtype=tf.float16):\n",
    "    return tf.data.Dataset.from_generator(lambda :datatape, output_types=(dtype, dtype), output_shapes=(datatape.shape, datatape.shape[:1]))\n",
    "\n",
    "train = to_tf(load_datatape(\"train_tape.h5\")).cache()\n",
    "valid = to_tf(load_datatape(\"valid_tape.h5\")).cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design and compile the NoobHeart model  \n",
    "\n",
    "NoobHeart is a model based on 3-dimensional convolutional neural networks (3D CNN), which is a very basic structure. It uses small 32x8x8 inputs, contains only 361 parameters, and is very simple and compact. The difference between it and ordinary 3D CNNs lies in the use of `LayerNorm` instead of `BatchNorm`.  \n",
    "You will use `tensorflow.keras` to complete this simple model and compile it. During compilation, the *optimizer* and *loss function* of the model will be specified, which are `Adam` and `MAE` respectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"NoobHeart\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer_normalization (LayerNo (None, 32, 8, 8, 3)       64        \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (None, 32, 4, 4, 4)       100       \n",
      "_________________________________________________________________\n",
      "layer_normalization_1 (Layer (None, 32, 4, 4, 4)       64        \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 32, 2, 2, 2)       66        \n",
      "_________________________________________________________________\n",
      "layer_normalization_2 (Layer (None, 32, 2, 2, 2)       64        \n",
      "_________________________________________________________________\n",
      "average_pooling3d (AveragePo (None, 32, 1, 1, 2)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 32, 1, 1, 1)       3         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "=================================================================\n",
      "Total params: 361\n",
      "Trainable params: 361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(32, 8, 8, 3)),\n",
    "    layers.LayerNormalization(axis=(1,)),\n",
    "    layers.Conv3D(4, (2, 2, 2), (1, 2, 2), padding='same', activation='tanh'),\n",
    "    layers.LayerNormalization(axis=(1,)),\n",
    "    layers.Conv3D(2, (2, 2, 2), (1, 2, 2), padding='same', activation='tanh'),\n",
    "    layers.LayerNormalization(axis=(1,)),\n",
    "    layers.AvgPool3D((1, 2, 2)),\n",
    "    layers.Conv3D(1, 1, 1),\n",
    "    layers.Flatten(),\n",
    "], name='NoobHeart')\n",
    "\n",
    "model.compile(optimizer='adam', loss='mae')\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the NoobHeart  \n",
    "Use `model.fit` to train the model.   \n",
    "\n",
    "`train.shuffle(n).batch(32)` means caching n data from the dataset and randomly drawing from the cache to shuffle the data. \n",
    "`.batch(32)` specifies batch_size is 32. \n",
    "`epochs=10` are the number of training rounds.   \n",
    "The callbacks specify functions that need to be called after each round of training, here adding a validation function, if the validation set loss decreases, then save this best model. \n",
    "After training is complete, read the saved best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "213/213 [==============================] - 12s 47ms/step - loss: 0.7243 - val_loss: 0.5985\n",
      "Epoch 2/10\n",
      "213/213 [==============================] - 10s 46ms/step - loss: 0.6190 - val_loss: 0.5574\n",
      "Epoch 3/10\n",
      "213/213 [==============================] - 10s 46ms/step - loss: 0.5890 - val_loss: 0.5364\n",
      "Epoch 4/10\n",
      "213/213 [==============================] - 10s 46ms/step - loss: 0.5724 - val_loss: 0.5272\n",
      "Epoch 5/10\n",
      "213/213 [==============================] - 10s 46ms/step - loss: 0.5634 - val_loss: 0.5220\n",
      "Epoch 6/10\n",
      "213/213 [==============================] - 10s 45ms/step - loss: 0.5594 - val_loss: 0.5217\n",
      "Epoch 7/10\n",
      "213/213 [==============================] - 10s 45ms/step - loss: 0.5568 - val_loss: 0.5191\n",
      "Epoch 8/10\n",
      "213/213 [==============================] - 10s 46ms/step - loss: 0.5552 - val_loss: 0.5233\n",
      "Epoch 9/10\n",
      "213/213 [==============================] - 10s 46ms/step - loss: 0.5536 - val_loss: 0.5178\n",
      "Epoch 10/10\n",
      "213/213 [==============================] - 10s 46ms/step - loss: 0.5524 - val_loss: 0.5170\n"
     ]
    }
   ],
   "source": [
    "valid_call = keras.callbacks.ModelCheckpoint('NoobHeart.h5', save_best_only=True, save_weights_only=True)\n",
    "model.fit(train.shuffle(9999).batch(32), validation_data=valid.batch(32), epochs=10, callbacks=[valid_call])\n",
    "model.load_weights('NoobHeart.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on UBFC  \n",
    "Use `eval_on_dataset` to test the model.  \n",
    "The first four parameters are: test_dataset, model, frames, resolution  \n",
    "`step=1` means that the model is applied to the test set every 1 second, and after completion, all outputs will be concatenated into a complete result. Overlapping parts will be averaged.  \n",
    "`save='../results/NoobHeart_PURE_UBFC.h5'` indicates the location to save the result file, please save it in the results folder for visualization.py to read.  \n",
    "`get_metrics` will read the result file and count the indicators. Generally, on UBFC, the metrics use the entire 1-minute video to calculate heart rate. If it is a longer video, using a sliding window would be more appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:05<00:00,  7.75it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Sliding window': {'MAE': 1.593, 'RMSE': 3.882, 'R': 0.97512},\n",
       " 'Whole video': {'MAE': 1.007, 'RMSE': 1.543, 'R': 0.99657}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_on_dataset('ubfc_dataset.h5', model, 32, (8, 8), step=0.5, batch=32, save='../results/NoobHeart_PURE_UBFC.h5')\n",
    "get_metrics('../results/NoobHeart_PURE_UBFC.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start your research  \n",
    "If your execution has no issues, you will get MAE: 1.1, RMSE: 1.6, R: 0.996 which is a pretty good result.   \n",
    "\n",
    "After the operation is completed, please return to the project directory (not in the Tutorial directory) and run `visualization.py`. This will display a visualization webpage.  \n",
    "\n",
    "You can go back to the \"Design model\" section, conduct ablation experiments or try modifying the model structure and develop your own model, you don't need to regenerate the datatape unless you've modified the input size of the model. UBFC is a simple dataset because it basically does not contain complex head movements; you can add more datasets following this tutorial's method and train and test on other datasets.   \n",
    "\n",
    "You can refer to the code I wrote in the benchmark, which includes our model and reproduces PhysNet, DeepPhys, TS-CAN, and PhysFormer. In this framework, developing and testing models is very simple. Once the dataset and datatape are generated, the development process is *adjusting the model -> training & validation -> testing*. Its speed is faster than any previous framework.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
